# -*- coding: utf-8 -*-
"""Untitled.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MztV0WFTjdZY1O1QjYBfrv4PlL6JmQOe
"""

import json

def parse_data(file):
    for l in open(file,'r'):
        yield json.loads(l)

data = list(parse_data('/content/Sarcasm_Headlines_Dataset.json'))

import pandas as pd

df = pd.DataFrame(data)

df

df.drop(['article_link'], axis=1,inplace=True)

df

df.shape

df.isnull().sum()

df['headline'][4]

"""## Normalizing the Text data"""

import nltk
nltk.download("stopwords")

import re
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer

ps = PorterStemmer()

col1 = df['headline']

corpus=[]
for i in range(len(df)):
    review= re.sub('[^a-zA-Z]', ' ', col1[i])
    review = review.lower()
    review = review.split()
    review = [ps.stem(word) for word in review if word not in set(stopwords.words('english'))]
    review= ' '.join(review)
    corpus.append(review)

corpus

from tensorflow.keras.preprocessing.text import one_hot

voc_size=10000

one_hot_rep = [one_hot(word,voc_size) for word in corpus]

one_hot_rep

from tensorflow.keras.layers import Embedding
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import SpatialDropout1D
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Bidirectional

sent_len=30
embedded_docs = pad_sequences(one_hot_rep, padding='pre', maxlen=sent_len)

embedded_docs

dimensions = 100

model=Sequential()
model.add(Embedding(voc_size,dimensions,input_length=sent_len))
model.add(SpatialDropout1D(0.4))
model.add(Bidirectional(LSTM(100,dropout=0.2)))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dense(128, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])
model.summary()

import numpy as np
X = np.array(embedded_docs)
y = np.array(df['is_sarcastic'])

y

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25, random_state=42)

y_train.shape

model.fit(X_train,y_train, epochs=5, batch_size=32, validation_data=(X_test,y_test))

y_pred = model.predict_classes(X_test)

y_pred

from sklearn.metrics import confusion_matrix
confusion_matrix(y_test,y_pred)

from sklearn.metrics import accuracy_score
accuracy_score(y_test,y_pred)

from sklearn.metrics import classification_report
print(classification_report(y_test,y_pred))

headline = 'Mom Warns Son to Watch Out for Idiots Rearâ€‘Ends His Motorcycle'
# headline = 'Cows lose their jobs as milk prices drop'
# headline = 'Man Accused of Killing Lawyer Receives a New Attorney'
# headline = 'India to have over two billion vaccine doses during Aug-Dec'
# headline = '15 more patients die at Goa Medical College due to oxygen shortage'
# headline = 'City Union Bank donates Rs 1 crore to Relief Fund'
headline_len = len(headline)

onehot=[one_hot(headline, headline_len)]
result = pad_sequences(onehot, padding='pre', maxlen=headline_len)

final = model.predict(result)
if final > 0.5:
  print("Sarcastic")
else:
  print("Not Sarcastic")

model.save("Sarcasm.h5")

